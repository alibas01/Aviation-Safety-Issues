{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from six.moves import range\n",
    "\n",
    "# Setup Pandas\n",
    "pd.set_option('display.width', 500)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.notebook_repr_html', True)\n",
    "\n",
    "# Setup Seaborn\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"poster\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    " df= pd.read_csv('database/extra/data_NLP.csv', index_col='idx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(91669, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pri_Problem</th>\n",
       "      <th>Synopsis</th>\n",
       "      <th>Narrative</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>idx</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Human Factors</td>\n",
       "      <td>SMA PENETRATED TCA ON CLIMB OUT.</td>\n",
       "      <td>THIS WAS MY FIRST DEP FROM BFI ON 31L. MY TURN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Human Factors</td>\n",
       "      <td>SMT PLT DESCENDED TO ARPT UNDERLYING TCA; ACCU...</td>\n",
       "      <td>A VFR FLT; BEING CONDUCTED UNDER FAR PART 91; ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Human Factors</td>\n",
       "      <td>LESS THAN STANDARD SEPARATION BETWEEN TWO ACR ...</td>\n",
       "      <td>ACR Y CLIMBING TO FL210 WAS STOPPED AT 160 FOR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Human Factors</td>\n",
       "      <td>ACR LTT LANDED AT THE WRONG ARPT; DESTINATION ...</td>\n",
       "      <td>SOME TIME HAD PASSED AFTER WE HAD PASSED THE R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Human Factors</td>\n",
       "      <td>LESS THAN STANDARD SEPARATION BETWEEN FLT OF 2...</td>\n",
       "      <td>ACFT X ON FINAL FOR RWY 30L (FLT OF 2) MISSED ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Pri_Problem                                           Synopsis                                          Narrative\n",
       "idx                                                                                                                     \n",
       "1    Human Factors                   SMA PENETRATED TCA ON CLIMB OUT.  THIS WAS MY FIRST DEP FROM BFI ON 31L. MY TURN...\n",
       "2    Human Factors  SMT PLT DESCENDED TO ARPT UNDERLYING TCA; ACCU...  A VFR FLT; BEING CONDUCTED UNDER FAR PART 91; ...\n",
       "6    Human Factors  LESS THAN STANDARD SEPARATION BETWEEN TWO ACR ...  ACR Y CLIMBING TO FL210 WAS STOPPED AT 160 FOR...\n",
       "7    Human Factors  ACR LTT LANDED AT THE WRONG ARPT; DESTINATION ...  SOME TIME HAD PASSED AFTER WE HAD PASSED THE R...\n",
       "8    Human Factors  LESS THAN STANDARD SEPARATION BETWEEN FLT OF 2...  ACFT X ON FINAL FOR RWY 30L (FLT OF 2) MISSED ..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Human Factors', 'Ambiguous', 'Weather', 'Airport', 'None',\n",
       "       'ATC Equipment / Nav Facility / Buildings', 'Aircraft',\n",
       "       'Chart Or Publication', 'Company Policy',\n",
       "       'Environment - Non Weather Related', 'Airspace Structure',\n",
       "       'Procedure', 'Manuals', 'Equipment / Tooling', 'Staffing', 'MEL',\n",
       "       'Logbook Entry', 'Incorrect / Not Installed / Unavailable Part'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Pri_Problem.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[~(df.Pri_Problem=='None')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(88071, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix=df.Pri_Problem.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Human Factors', 'Ambiguous', 'Weather', 'Airport',\n",
       "       'ATC Equipment / Nav Facility / Buildings', 'Aircraft',\n",
       "       'Chart Or Publication', 'Company Policy',\n",
       "       'Environment - Non Weather Related', 'Airspace Structure',\n",
       "       'Procedure', 'Manuals', 'Equipment / Tooling', 'Staffing', 'MEL',\n",
       "       'Logbook Entry', 'Incorrect / Not Installed / Unavailable Part'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Pri_Problem.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "def make_xy(df, category, vectorizer=None):     \n",
    "    if vectorizer is None:\n",
    "        vectorizer = CountVectorizer()\n",
    "    X = vectorizer.fit_transform(df.Synopsis)\n",
    "    X = X.tocsc()  \n",
    "    y = (df.Pri_Problem == category).values.astype(np.int)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_HF=df.copy()\n",
    "df_ambiguous=df.copy()\n",
    "df_weather=df.copy()\n",
    "df_airport=df.copy()\n",
    "df_atc=df.copy()\n",
    "df_aircraft=df.copy()\n",
    "df_publication=df.copy()\n",
    "df_company=df.copy()\n",
    "df_environment=df.copy()\n",
    "df_airspace=df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<88071x22960 sparse matrix of type '<class 'numpy.int64'>'\n",
       " \twith 1647331 stored elements in Compressed Sparse Column format>,\n",
       " array([1, 1, 1, ..., 0, 0, 0]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_xy(df_HF, 'Human Factors')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Human Factors - MNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Scores for the Training set : 0.8058524874693831  and Test Set : 0.79218075845886\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X, y = make_xy(df_HF, 'Human Factors')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3, random_state=11)\n",
    "\n",
    "Mul_NB = MultinomialNB()\n",
    "model=Mul_NB.fit(X_train, y_train)\n",
    "\n",
    "TrainingAccuracy = Mul_NB.score(X_train,y_train)\n",
    "\n",
    "y_pred = Mul_NB.predict(X_test)\n",
    "\n",
    "TestAccuracy = accuracy_score(y_test, y_pred)\n",
    "ttacc = Mul_NB.score(X_test,y_test)\n",
    "\n",
    "print('Accuracy Scores for the Training set : {0}  and Test Set : {1}'.format(TrainingAccuracy, \n",
    "                                                                                         TestAccuracy))\n",
    "print(ttacc==TestAccuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3947  2239]\n",
      " [ 3252 16984]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "m, n = X.shape\n",
    "sX = X.toarray().sum(axis=0)\n",
    "\n",
    "\n",
    "sY = [np.sum(sX <= x) for x in range(m)]\n",
    "ax = plt.plot(sY[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "def cv_score(df, X, y, scorefunc):\n",
    "    result = 0.\n",
    "    nfold = 5\n",
    "    for train, test in KFold(nfold).split(X): # split data into train/test groups, 5 times\n",
    "        df.fit(X[train], y[train]) # fit the classifier, passed is as clf.\n",
    "        result += scorefunc(df, X[test], y[test]) # evaluate score function on held-out data\n",
    "    return result / nfold # average\n",
    "\n",
    "def log_likelihood(df, x, y):\n",
    "    prob = df.predict_log_proba(x)\n",
    "    not_reason = y == 0\n",
    "    reason = ~not_reason\n",
    "    return prob[not_reason, 0].sum() + prob[reason, 1].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha: 1\n",
      "min_df: 0.0001\n"
     ]
    }
   ],
   "source": [
    "alphas = [.1, 1, 5, 10, 50]\n",
    "min_dfs = [1e-5, 1e-4, 1e-3, 1e-2, 1e-1] # YOUR TURN: put your value of min_df here.\n",
    "\n",
    "#Find the best value for alpha and min_df, and the best classifier\n",
    "best_alpha = None\n",
    "best_min_df = None\n",
    "maxscore=-np.inf\n",
    "for (alpha,min_df) in zip(alphas,min_dfs):        \n",
    "    vectorizer = CountVectorizer(min_df=min_df)       \n",
    "    Xthis, ythis = make_xy(df_HF, 'Human Factors')\n",
    "    Xtrainthis = Xthis[mask]\n",
    "    ytrainthis = ythis[mask]\n",
    "   \n",
    "    mod = MultinomialNB(alpha=alpha)\n",
    "    score = cv_score(mod, Xtrainthis, ytrainthis, log_likelihood)\n",
    "    if score > maxscore:\n",
    "        maxscore = score\n",
    "        best_alpha, best_min_df = alpha, min_df\n",
    "        \n",
    "print(\"alpha: {}\".format(best_alpha))\n",
    "\n",
    "print (\"min_df: {}\".format(best_min_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#from sklearn.model_selection import train_test_split\n",
    "_, itest = train_test_split(range(df_HF.shape[0]), train_size=0.7)\n",
    "mask = np.zeros(df_HF.shape[0], dtype=np.bool)\n",
    "mask[itest] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Human Factors - TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training data: 0.805852\n",
      "Accuracy on test data:     0.792181\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidfvectorizer = TfidfVectorizer(min_df = best_min_df, stop_words = \"english\")\n",
    "vectorizer = CountVectorizer(min_df=best_min_df)\n",
    "x, y = make_xy(df_HF, 'Human Factors', tfidfvectorizer)\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=.3, random_state=11)\n",
    "\n",
    "mod = MultinomialNB(alpha = best_alpha).fit(x_train, y_train)\n",
    "\n",
    "training_accuracy = mod.score(x_train, y_train)\n",
    "test_accuracy = mod.score(x_test, y_test)\n",
    "\n",
    "print(\"Accuracy on training data: {:2f}\".format(training_accuracy))\n",
    "print(\"Accuracy on test data:     {:2f}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ambiguous - MNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Scores for the Training set : 0.916073253418547  and Test Set : 0.8995155552191356\n",
      "True\n",
      "[[23434  1418]\n",
      " [ 1237   333]]\n"
     ]
    }
   ],
   "source": [
    "X, y = make_xy(df_weather, 'Ambiguous')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3, random_state=11)\n",
    "\n",
    "Mul_NB = MultinomialNB()\n",
    "Mul_NB.fit(X_train, y_train)\n",
    "\n",
    "TrainingAccuracy = Mul_NB.score(X_train,y_train)\n",
    "\n",
    "y_pred = Mul_NB.predict(X_test)\n",
    "\n",
    "TestAccuracy = accuracy_score(y_test, y_pred)\n",
    "ttacc = Mul_NB.score(X_test,y_test)\n",
    "\n",
    "print('Accuracy Scores for the Training set : {0}  and Test Set : {1}'.format(TrainingAccuracy, \n",
    "                                                                                         TestAccuracy))\n",
    "print(ttacc==TestAccuracy)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weather - MNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Scores for the Training set : 0.9714026180473325  and Test Set : 0.9678676860192263\n",
      "True\n",
      "[[25167   365]\n",
      " [  484   406]]\n"
     ]
    }
   ],
   "source": [
    "X, y = make_xy(df_ambiguous, 'Weather')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3, random_state=11)\n",
    "\n",
    "Mul_NB = MultinomialNB()\n",
    "Mul_NB.fit(X_train, y_train)\n",
    "\n",
    "TrainingAccuracy = Mul_NB.score(X_train,y_train)\n",
    "\n",
    "y_pred = Mul_NB.predict(X_test)\n",
    "\n",
    "TestAccuracy = accuracy_score(y_test, y_pred)\n",
    "ttacc = Mul_NB.score(X_test,y_test)\n",
    "\n",
    "print('Accuracy Scores for the Training set : {0}  and Test Set : {1}'.format(TrainingAccuracy, \n",
    "                                                                                         TestAccuracy))\n",
    "print(ttacc==TestAccuracy)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Airport - MNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Scores for the Training set : 0.9906730036172525  and Test Set : 0.9902354098857014\n",
      "True\n",
      "[[26156    50]\n",
      " [  208     8]]\n"
     ]
    }
   ],
   "source": [
    "X, y = make_xy(df_airport, 'Airport')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3, random_state=11)\n",
    "\n",
    "Mul_NB = MultinomialNB()\n",
    "Mul_NB.fit(X_train, y_train)\n",
    "\n",
    "TrainingAccuracy = Mul_NB.score(X_train,y_train)\n",
    "\n",
    "y_pred = Mul_NB.predict(X_test)\n",
    "\n",
    "TestAccuracy = accuracy_score(y_test, y_pred)\n",
    "ttacc = Mul_NB.score(X_test,y_test)\n",
    "\n",
    "print('Accuracy Scores for the Training set : {0}  and Test Set : {1}'.format(TrainingAccuracy, \n",
    "                                                                                         TestAccuracy))\n",
    "print(ttacc==TestAccuracy)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ATC Equipment / Nav Facility / Buildings - MNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Scores for the Training set : 0.9905756784376064  and Test Set : 0.9892892286730754\n",
      "True\n",
      "[[26090    47]\n",
      " [  236    49]]\n"
     ]
    }
   ],
   "source": [
    "X, y = make_xy(df_atc, 'ATC Equipment / Nav Facility / Buildings')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3, random_state=11)\n",
    "\n",
    "Mul_NB = MultinomialNB()\n",
    "Mul_NB.fit(X_train, y_train)\n",
    "\n",
    "TrainingAccuracy = Mul_NB.score(X_train,y_train)\n",
    "\n",
    "y_pred = Mul_NB.predict(X_test)\n",
    "\n",
    "TestAccuracy = accuracy_score(y_test, y_pred)\n",
    "ttacc = Mul_NB.score(X_test,y_test)\n",
    "\n",
    "print('Accuracy Scores for the Training set : {0}  and Test Set : {1}'.format(TrainingAccuracy, \n",
    "                                                                                         TestAccuracy))\n",
    "print(ttacc==TestAccuracy)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aircraft - MNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Scores for the Training set : 0.9830491978783111  and Test Set : 0.9802437362803724\n",
      "True\n",
      "[[25896    97]\n",
      " [  425     4]]\n"
     ]
    }
   ],
   "source": [
    "X, y = make_xy(df_aircraft, 'Aircraft')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3, random_state=11)\n",
    "\n",
    "Mul_NB = MultinomialNB()\n",
    "Mul_NB.fit(X_train, y_train)\n",
    "\n",
    "TrainingAccuracy = Mul_NB.score(X_train,y_train)\n",
    "\n",
    "y_pred = Mul_NB.predict(X_test)\n",
    "\n",
    "TestAccuracy = accuracy_score(y_test, y_pred)\n",
    "ttacc = Mul_NB.score(X_test,y_test)\n",
    "\n",
    "print('Accuracy Scores for the Training set : {0}  and Test Set : {1}'.format(TrainingAccuracy, \n",
    "                                                                                         TestAccuracy))\n",
    "print(ttacc==TestAccuracy)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chart Or Publication - MNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_xy(df_publication, 'Chart Or Publication')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3, random_state=11)\n",
    "\n",
    "Mul_NB = MultinomialNB()\n",
    "Mul_NB.fit(X_train, y_train)\n",
    "\n",
    "TrainingAccuracy = Mul_NB.score(X_train,y_train)\n",
    "\n",
    "y_pred = Mul_NB.predict(X_test)\n",
    "\n",
    "TestAccuracy = accuracy_score(y_test, y_pred)\n",
    "ttacc = Mul_NB.score(X_test,y_test)\n",
    "\n",
    "print('Accuracy Scores for the Training set : {0}  and Test Set : {1}'.format(TrainingAccuracy, \n",
    "                                                                                         TestAccuracy))\n",
    "print(ttacc==TestAccuracy)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Company Policy - MNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Scores for the Training set : 0.9509805511849341  and Test Set : 0.9458784346378019\n",
      "True\n",
      "[[24521  1124]\n",
      " [  306   471]]\n"
     ]
    }
   ],
   "source": [
    "X, y = make_xy(df_company, 'Company Policy')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3, random_state=11)\n",
    "\n",
    "Mul_NB = MultinomialNB()\n",
    "Mul_NB.fit(X_train, y_train)\n",
    "\n",
    "TrainingAccuracy = Mul_NB.score(X_train,y_train)\n",
    "\n",
    "y_pred = Mul_NB.predict(X_test)\n",
    "\n",
    "TestAccuracy = accuracy_score(y_test, y_pred)\n",
    "ttacc = Mul_NB.score(X_test,y_test)\n",
    "\n",
    "print('Accuracy Scores for the Training set : {0}  and Test Set : {1}'.format(TrainingAccuracy, \n",
    "                                                                                         TestAccuracy))\n",
    "print(ttacc==TestAccuracy)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment - Non Weather Related - MNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Scores for the Training set : 0.9936414215964574  and Test Set : 0.9929982590265688\n",
      "True\n",
      "[[26237    22]\n",
      " [  163     0]]\n"
     ]
    }
   ],
   "source": [
    "X, y = make_xy(df_environment, 'Environment - Non Weather Related')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3, random_state=11)\n",
    "\n",
    "Mul_NB = MultinomialNB()\n",
    "Mul_NB.fit(X_train, y_train)\n",
    "\n",
    "TrainingAccuracy = Mul_NB.score(X_train,y_train)\n",
    "\n",
    "y_pred = Mul_NB.predict(X_test)\n",
    "\n",
    "TestAccuracy = accuracy_score(y_test, y_pred)\n",
    "ttacc = Mul_NB.score(X_test,y_test)\n",
    "\n",
    "print('Accuracy Scores for the Training set : {0}  and Test Set : {1}'.format(TrainingAccuracy, \n",
    "                                                                                         TestAccuracy))\n",
    "print(ttacc==TestAccuracy)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Airspace Structure - MNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Scores for the Training set : 0.989797077000438  and Test Set : 0.9885322837029747\n",
      "True\n",
      "[[26118    40]\n",
      " [  263     1]]\n"
     ]
    }
   ],
   "source": [
    "X, y = make_xy(df_airspace, 'Airspace Structure')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3, random_state=11)\n",
    "\n",
    "Mul_NB = MultinomialNB()\n",
    "Mul_NB.fit(X_train, y_train)\n",
    "\n",
    "TrainingAccuracy = Mul_NB.score(X_train,y_train)\n",
    "\n",
    "y_pred = Mul_NB.predict(X_test)\n",
    "\n",
    "TestAccuracy = accuracy_score(y_test, y_pred)\n",
    "ttacc = Mul_NB.score(X_test,y_test)\n",
    "\n",
    "print('Accuracy Scores for the Training set : {0}  and Test Set : {1}'.format(TrainingAccuracy, \n",
    "                                                                                         TestAccuracy))\n",
    "print(ttacc==TestAccuracy)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TOP 3 Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "top3=['Human Factors', 'Ambiguous','Procedure']\n",
    "df_top3=df[df.Pri_Problem.isin(top3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(76692, 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_top3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pri_Problem</th>\n",
       "      <th>Synopsis</th>\n",
       "      <th>Narrative</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>idx</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Human Factors</td>\n",
       "      <td>SMA PENETRATED TCA ON CLIMB OUT.</td>\n",
       "      <td>THIS WAS MY FIRST DEP FROM BFI ON 31L. MY TURN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Human Factors</td>\n",
       "      <td>SMT PLT DESCENDED TO ARPT UNDERLYING TCA; ACCU...</td>\n",
       "      <td>A VFR FLT; BEING CONDUCTED UNDER FAR PART 91; ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Human Factors</td>\n",
       "      <td>LESS THAN STANDARD SEPARATION BETWEEN TWO ACR ...</td>\n",
       "      <td>ACR Y CLIMBING TO FL210 WAS STOPPED AT 160 FOR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Human Factors</td>\n",
       "      <td>ACR LTT LANDED AT THE WRONG ARPT; DESTINATION ...</td>\n",
       "      <td>SOME TIME HAD PASSED AFTER WE HAD PASSED THE R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Human Factors</td>\n",
       "      <td>LESS THAN STANDARD SEPARATION BETWEEN FLT OF 2...</td>\n",
       "      <td>ACFT X ON FINAL FOR RWY 30L (FLT OF 2) MISSED ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Pri_Problem                                           Synopsis                                          Narrative\n",
       "idx                                                                                                                     \n",
       "1    Human Factors                   SMA PENETRATED TCA ON CLIMB OUT.  THIS WAS MY FIRST DEP FROM BFI ON 31L. MY TURN...\n",
       "2    Human Factors  SMT PLT DESCENDED TO ARPT UNDERLYING TCA; ACCU...  A VFR FLT; BEING CONDUCTED UNDER FAR PART 91; ...\n",
       "6    Human Factors  LESS THAN STANDARD SEPARATION BETWEEN TWO ACR ...  ACR Y CLIMBING TO FL210 WAS STOPPED AT 160 FOR...\n",
       "7    Human Factors  ACR LTT LANDED AT THE WRONG ARPT; DESTINATION ...  SOME TIME HAD PASSED AFTER WE HAD PASSED THE R...\n",
       "8    Human Factors  LESS THAN STANDARD SEPARATION BETWEEN FLT OF 2...  ACFT X ON FINAL FOR RWY 30L (FLT OF 2) MISSED ..."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_top3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Human Factors', 'Ambiguous', 'Procedure'], dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_top3.Pri_Problem.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Scores for the Training set : 0.8250689218389091  and Test Set : 0.8140212100139083\n",
      "True\n",
      "[[  467   862   253]\n",
      " [ 1427 17276  1502]\n",
      " [  217    18   986]]\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Ambiguous       0.22      0.30      0.25      1582\n",
      "Human Factors       0.95      0.86      0.90     20205\n",
      "    Procedure       0.36      0.81      0.50      1221\n",
      "\n",
      "    micro avg       0.81      0.81      0.81     23008\n",
      "    macro avg       0.51      0.65      0.55     23008\n",
      " weighted avg       0.87      0.81      0.83     23008\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X=vectorizer.fit_transform(df_top3.Synopsis)\n",
    "y=df_top3.Pri_Problem\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3, random_state=11)\n",
    "\n",
    "Mul_NB = MultinomialNB()\n",
    "Mul_NB.fit(X_train, y_train)\n",
    "\n",
    "TrainingAccuracy = Mul_NB.score(X_train,y_train)\n",
    "\n",
    "y_pred = Mul_NB.predict(X_test)\n",
    "\n",
    "TestAccuracy = accuracy_score(y_test, y_pred)\n",
    "ttacc = Mul_NB.score(X_test,y_test)\n",
    "\n",
    "print('Accuracy Scores for the Training set : {0}  and Test Set : {1}'.format(TrainingAccuracy, \n",
    "                                                                                         TestAccuracy))\n",
    "print(ttacc==TestAccuracy)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print()\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFIDF  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Scores for the Training set : 0.8832054243349974  and Test Set : 0.8786509040333796\n",
      "True\n",
      "[[    2  1577     6]\n",
      " [    6 20143    34]\n",
      " [    2  1167    71]]\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Ambiguous       0.20      0.00      0.00      1585\n",
      "Human Factors       0.88      1.00      0.94     20183\n",
      "    Procedure       0.64      0.06      0.11      1240\n",
      "\n",
      "    micro avg       0.88      0.88      0.88     23008\n",
      "    macro avg       0.57      0.35      0.35     23008\n",
      " weighted avg       0.82      0.88      0.83     23008\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "X = tfidf.fit_transform(df_top3.Synopsis)\n",
    "y=df_top3.Pri_Problem\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3, random_state=19)\n",
    "\n",
    "clf = MultinomialNB().fit(X_train, y_train)\n",
    "\n",
    "TrainingAccuracy = clf.score(X_train,y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "TestAccuracy = accuracy_score(y_test, y_pred)\n",
    "ttacc = clf.score(X_test,y_test)\n",
    "\n",
    "print('Accuracy Scores for the Training set : {0}  and Test Set : {1}'.format(TrainingAccuracy, \n",
    "                                                                                         TestAccuracy))\n",
    "print(ttacc==TestAccuracy)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print()\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Scores for the Training set : 0.9219506743163699  and Test Set : 0.885778859527121\n",
      "True\n",
      "[[  207  1287    91]\n",
      " [  250 19642   291]\n",
      " [  112   597   531]]\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Ambiguous       0.36      0.13      0.19      1585\n",
      "Human Factors       0.91      0.97      0.94     20183\n",
      "    Procedure       0.58      0.43      0.49      1240\n",
      "\n",
      "    micro avg       0.89      0.89      0.89     23008\n",
      "    macro avg       0.62      0.51      0.54     23008\n",
      " weighted avg       0.86      0.89      0.87     23008\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X=vectorizer.fit_transform(df_top3.Synopsis)\n",
    "y=df_top3.Pri_Problem\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3, random_state=19)\n",
    "\n",
    "\n",
    "log = LogisticRegression().fit(X_train, y_train)\n",
    "\n",
    "TrainingAccuracy = log.score(X_train,y_train)\n",
    "\n",
    "y_pred = log.predict(X_test)\n",
    "\n",
    "TestAccuracy = accuracy_score(y_test, y_pred)\n",
    "ttacc = log.score(X_test,y_test)\n",
    "\n",
    "print('Accuracy Scores for the Training set : {0}  and Test Set : {1}'.format(TrainingAccuracy, \n",
    "                                                                                         TestAccuracy))\n",
    "print(ttacc==TestAccuracy)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print()\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Scores for the Training set : 0.8861113180836003  and Test Set : 0.882519123783032\n",
      "True\n",
      "[[   24  1535    26]\n",
      " [   13 19978   192]\n",
      " [   26   911   303]]\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Ambiguous       0.38      0.02      0.03      1585\n",
      "Human Factors       0.89      0.99      0.94     20183\n",
      "    Procedure       0.58      0.24      0.34      1240\n",
      "\n",
      "    micro avg       0.88      0.88      0.88     23008\n",
      "    macro avg       0.62      0.42      0.44     23008\n",
      " weighted avg       0.84      0.88      0.84     23008\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "X=vectorizer.fit_transform(df_top3.Synopsis)\n",
    "y=df_top3.Pri_Problem\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3, random_state=19)\n",
    "\n",
    "clf = DecisionTreeClassifier(criterion=\"entropy\", max_depth=5)\n",
    "clf = clf.fit(X_train,y_train)\n",
    "\n",
    "TrainingAccuracy = clf.score(X_train,y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "TestAccuracy = accuracy_score(y_test, y_pred)\n",
    "ttacc = clf.score(X_test,y_test)\n",
    "\n",
    "print('Accuracy Scores for the Training set : {0}  and Test Set : {1}'.format(TrainingAccuracy, \n",
    "                                                                                         TestAccuracy))\n",
    "print(ttacc==TestAccuracy)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print()\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Scores for the Training set : 0.9988637210342002  and Test Set : 0.8858657858136301\n",
      "True\n",
      "[[   33  1549     3]\n",
      " [   16 20105    62]\n",
      " [   17   979   244]]\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Ambiguous       0.50      0.02      0.04      1585\n",
      "Human Factors       0.89      1.00      0.94     20183\n",
      "    Procedure       0.79      0.20      0.32      1240\n",
      "\n",
      "    micro avg       0.89      0.89      0.89     23008\n",
      "    macro avg       0.73      0.40      0.43     23008\n",
      " weighted avg       0.86      0.89      0.84     23008\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "X=vectorizer.fit_transform(df_top3.Synopsis)\n",
    "y=df_top3.Pri_Problem\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3, random_state=19)\n",
    "\n",
    "clf=RandomForestClassifier(n_estimators=100)\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "TrainingAccuracy = clf.score(X_train,y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "TestAccuracy = accuracy_score(y_test, y_pred)\n",
    "ttacc = clf.score(X_test,y_test)\n",
    "\n",
    "print('Accuracy Scores for the Training set : {0}  and Test Set : {1}'.format(TrainingAccuracy, \n",
    "                                                                                         TestAccuracy))\n",
    "print(ttacc==TestAccuracy)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print()\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning with Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.885\n",
      "Best parameters set:\n",
      "\trfc__class_weight: None\n",
      "\trfc__max_depth: None\n",
      "\trfc__max_features: 'sqrt'\n",
      "\trfc__n_estimators: 200\n",
      "\tvect__ngram_range: (1, 1)\n",
      "Accuracy on training data: 0.998864\n",
      "Accuracy on test data:     0.883736\n",
      "[[   26  1557     2]\n",
      " [   11 20128    44]\n",
      " [   15  1046   179]]\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Ambiguous       0.50      0.02      0.03      1585\n",
      "Human Factors       0.89      1.00      0.94     20183\n",
      "    Procedure       0.80      0.14      0.24      1240\n",
      "\n",
      "    micro avg       0.88      0.88      0.88     23008\n",
      "    macro avg       0.73      0.39      0.40     23008\n",
      " weighted avg       0.85      0.88      0.84     23008\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble  import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def evaluate(grid_search, clf, Xtrain, Xtest, ytrain, ytest):\n",
    "    print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "    print(\"Best parameters set:\")\n",
    "    best_parameters = grid_search.best_estimator_.get_params()\n",
    "    for param_name in sorted(parameters.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "\n",
    "    training_accuracy = clf.score(Xtrain, ytrain)\n",
    "    test_accuracy = clf.score(Xtest, ytest)\n",
    "    print(\"Accuracy on training data: {:2f}\".format(training_accuracy))\n",
    "    print(\"Accuracy on test data:     {:2f}\".format(test_accuracy))\n",
    "\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    print(confusion_matrix(ytest, clf.predict(Xtest)))\n",
    "    print()\n",
    "    print(\"Classification Report\")\n",
    "    print(classification_report(ytest, clf.predict(Xtest)))\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    #('gbm', GradientBoostingClassifier()),\n",
    "    ('rfc', RandomForestClassifier()),\n",
    "])\n",
    "\n",
    "parameters = {\n",
    "    'vect__ngram_range': [(1,1), (1, 2)],\n",
    "    #'gbm__n_estimators': [100,200,300],\n",
    "    #'gbm__max_depth': [15,30,None],\n",
    "    #'gbm__max_features': ['sqrt','log2'],\n",
    "    'rfc__n_estimators': [100,200,300],\n",
    "    'rfc__max_depth': [15,30,None],\n",
    "    'rfc__max_features': ['sqrt','log2'],\n",
    "    'rfc__class_weight': ['balanced', None]    \n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1)\n",
    "\n",
    "X=df_top3.Synopsis\n",
    "y=df_top3.Pri_Problem\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3, random_state=19)\n",
    "\n",
    "clf = grid_search.fit(X_train, y_train)\n",
    "evaluate(grid_search, clf, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Scores for the Training set : 0.8949221369495567  and Test Set : 0.8867350486787204\n",
      "True\n",
      "[[   80  1483    22]\n",
      " [   55 19939   189]\n",
      " [   45   812   383]]\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Ambiguous       0.44      0.05      0.09      1585\n",
      "Human Factors       0.90      0.99      0.94     20183\n",
      "    Procedure       0.64      0.31      0.42      1240\n",
      "\n",
      "    micro avg       0.89      0.89      0.89     23008\n",
      "    macro avg       0.66      0.45      0.48     23008\n",
      " weighted avg       0.85      0.89      0.85     23008\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
    "\n",
    "X=vectorizer.fit_transform(df_top3.Synopsis)\n",
    "y=df_top3.Pri_Problem\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3, random_state=19)\n",
    "\n",
    "gb = GradientBoostingClassifier()\n",
    "gb.fit(X_train, y_train)\n",
    "    \n",
    "TrainingAccuracy = gb.score(X_train,y_train)\n",
    "\n",
    "y_pred = gb.predict(X_test)\n",
    "\n",
    "TestAccuracy = accuracy_score(y_test, y_pred)\n",
    "ttacc = gb.score(X_test,y_test)\n",
    "\n",
    "print('Accuracy Scores for the Training set : {0}  and Test Set : {1}'.format(TrainingAccuracy, \n",
    "                                                                                         TestAccuracy))\n",
    "print(ttacc==TestAccuracy)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print()\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning with GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.890\n",
      "Best parameters set:\n",
      "\tgbm__max_depth: 30\n",
      "\tgbm__max_features: 'sqrt'\n",
      "\tgbm__n_estimators: 200\n",
      "\tvect__ngram_range: (1, 2)\n",
      "Accuracy on training data: 0.968873\n",
      "Accuracy on test data:     0.887170\n",
      "[[   81  1474    30]\n",
      " [   51 19960   172]\n",
      " [   39   830   371]]\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Ambiguous       0.47      0.05      0.09      1585\n",
      "Human Factors       0.90      0.99      0.94     20183\n",
      "    Procedure       0.65      0.30      0.41      1240\n",
      "\n",
      "    micro avg       0.89      0.89      0.89     23008\n",
      "    macro avg       0.67      0.45      0.48     23008\n",
      " weighted avg       0.85      0.89      0.85     23008\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble  import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def evaluate(grid_search, clf, Xtrain, Xtest, ytrain, ytest):\n",
    "    print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "    print(\"Best parameters set:\")\n",
    "    best_parameters = grid_search.best_estimator_.get_params()\n",
    "    for param_name in sorted(parameters.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "\n",
    "    training_accuracy = clf.score(Xtrain, ytrain)\n",
    "    test_accuracy = clf.score(Xtest, ytest)\n",
    "    print(\"Accuracy on training data: {:2f}\".format(training_accuracy))\n",
    "    print(\"Accuracy on test data:     {:2f}\".format(test_accuracy))\n",
    "\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    print(confusion_matrix(ytest, clf.predict(Xtest)))\n",
    "    print()\n",
    "    print(\"Classification Report\")\n",
    "    print(classification_report(ytest, clf.predict(Xtest)))\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('gbm', GradientBoostingClassifier()),\n",
    "    #('rfc', RandomForestClassifier()),\n",
    "])\n",
    "\n",
    "parameters = {\n",
    "    'vect__ngram_range': [(1,1), (1, 2)],\n",
    "    'gbm__n_estimators': [100,200,300],\n",
    "    'gbm__max_depth': [15,30,None],\n",
    "    'gbm__max_features': ['sqrt','log2'],\n",
    "    #'rfc__n_estimators': [100,200,300],\n",
    "    #'rfc__max_depth': [15,30,None],\n",
    "    #'rfc__max_features': ['sqrt','log2'],\n",
    "    #'rfc__class_weight': ['balanced', None]    \n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1)\n",
    "\n",
    "X=df_top3.Synopsis\n",
    "y=df_top3.Pri_Problem\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3, random_state=19)\n",
    "\n",
    "clf = grid_search.fit(X_train, y_train)\n",
    "evaluate(grid_search, clf, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top 6 Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "top6=['Human Factors', 'Ambiguous','Procedure','Weather', 'Company Policy', 'Aircraft']\n",
    "df_top6=df[df.Pri_Problem.isin(top6)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Top 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Scores for the Training set : 0.9980547070969064  and Test Set : 0.8213887561713649\n",
      "True\n",
      "[[   13     1     0   411     7     2]\n",
      " [    2    34     3  1523     3     7]\n",
      " [    0     0    59   722    19     1]\n",
      " [   16    19    10 20020    44    47]\n",
      " [    0    15     1   968   264     1]\n",
      " [    1     0     1   642    20   240]]\n",
      "\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "      Aircraft       0.41      0.03      0.06       434\n",
      "     Ambiguous       0.49      0.02      0.04      1572\n",
      "Company Policy       0.80      0.07      0.13       801\n",
      " Human Factors       0.82      0.99      0.90     20156\n",
      "     Procedure       0.74      0.21      0.33      1249\n",
      "       Weather       0.81      0.27      0.40       904\n",
      "\n",
      "     micro avg       0.82      0.82      0.82     25116\n",
      "     macro avg       0.68      0.27      0.31     25116\n",
      "  weighted avg       0.79      0.82      0.76     25116\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "X=vectorizer.fit_transform(df_top6.Synopsis)\n",
    "y=df_top6.Pri_Problem\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3, random_state=19)\n",
    "\n",
    "clf=RandomForestClassifier(n_estimators=100)\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "TrainingAccuracy = clf.score(X_train,y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "TestAccuracy = accuracy_score(y_test, y_pred)\n",
    "ttacc = clf.score(X_test,y_test)\n",
    "\n",
    "print('Accuracy Scores for the Training set : {0}  and Test Set : {1}'.format(TrainingAccuracy, \n",
    "                                                                                         TestAccuracy))\n",
    "print(ttacc==TestAccuracy)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print()\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GBM Top 6 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Scores for the Training set : 0.8385406890432231  and Test Set : 0.8219461697722568\n",
      "True\n",
      "[[   19     2     2   393    14     4]\n",
      " [    1    54    31  1423    28    35]\n",
      " [    3     4   107   656    28     3]\n",
      " [   19    34    51 19794   161    97]\n",
      " [    1    29    18   829   366     6]\n",
      " [    3     1     3   560    33   304]]\n",
      "\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "      Aircraft       0.41      0.04      0.08       434\n",
      "     Ambiguous       0.44      0.03      0.06      1572\n",
      "Company Policy       0.50      0.13      0.21       801\n",
      " Human Factors       0.84      0.98      0.90     20156\n",
      "     Procedure       0.58      0.29      0.39      1249\n",
      "       Weather       0.68      0.34      0.45       904\n",
      "\n",
      "     micro avg       0.82      0.82      0.82     25116\n",
      "     macro avg       0.57      0.30      0.35     25116\n",
      "  weighted avg       0.78      0.82      0.77     25116\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
    "\n",
    "X=vectorizer.fit_transform(df_top6.Synopsis)\n",
    "y=df_top6.Pri_Problem\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3, random_state=19)\n",
    "\n",
    "gb = GradientBoostingClassifier()\n",
    "gb.fit(X_train, y_train)\n",
    "    \n",
    "TrainingAccuracy = gb.score(X_train,y_train)\n",
    "\n",
    "y_pred = gb.predict(X_test)\n",
    "\n",
    "TestAccuracy = accuracy_score(y_test, y_pred)\n",
    "ttacc = gb.score(X_test,y_test)\n",
    "\n",
    "print('Accuracy Scores for the Training set : {0}  and Test Set : {1}'.format(TrainingAccuracy, \n",
    "                                                                                         TestAccuracy))\n",
    "print(ttacc==TestAccuracy)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print()\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
